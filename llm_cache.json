{
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/pocketflow/__init__.py'.\nUnit Name: __init__.py\n\nCode:\nimport asyncio, warnings, copy, time\n\nclass BaseNode:\n    def __init__(self): self.params,self.successors={},{}\n    def set_params(self,params): self.params=params\n    def next(self,node,action=\"default\"):\n        if action in self.successors: warnings.warn(f\"Overwriting successor for action '{action}'\")\n        self.successors[action]=node; return node\n    def prep(self,shared): pass\n    def exec(self,prep_res): pass\n    def post(self,shared,prep_res,exec_res): pass\n    def _exec(self,prep_res): return self.exec(prep_res)\n    def _run(self,shared): p=self.prep(shared); e=self._exec(p); return self.post(shared,p,e)\n    def run(self,shared): \n        if self.successors: warnings.warn(\"Node won't run successors. Use Flow.\")  \n        return self._run(shared)\n    def __rshift__(self,other): return self.next(other)\n    def __sub__(self,action):\n        if isinstance(action,str): return _ConditionalTransition(self,action)\n        raise TypeError(\"Action must be a string\")\n\nclass _ConditionalTransition:\n    def __init__(self,src,action): self.src,self.action=src,action\n    def __rshift__(self,tgt): return self.src.next(tgt,self.action)\n\nclass Node(BaseNode):\n    def __init__(self,max_retries=1,wait=0): super().__init__(); self.max_retries,self.wait=max_retries,wait\n    def exec_fallback(self,prep_res,exc): raise exc\n    def _exec(self,prep_res):\n        for self.cur_retry in range(self.max_retries):\n            try: return self.exec(prep_res)\n            except Exception as e:\n                if self.cur_retry==self.max_retries-1: return self.exec_fallback(prep_res,e)\n                if self.wait>0: time.sleep(self.wait)\n\nclass BatchNode(Node):\n    def _exec(self,items): return [super(BatchNode,self)._exec(i) for i in (items or [])]\n\nclass Flow(BaseNode):\n    def __init__(self,start=None): super().__init__(); self.start_node=start\n    def start(self,start): self.start_node=start; return start\n    def get_next_node(self,curr,action):\n        nxt=curr.successors.get(action or \"default\")\n        if not nxt and curr.successors: warnings.warn(f\"Flow ends: '{action}' not found in {list(curr.successors)}\")\n        return nxt\n    def _orch(self,shared,params=None):\n        curr,p,last_action =copy.copy(self.start_node),(params or {**self.params}),None\n        while curr: curr.set_params(p); last_action=curr._run(shared); curr=copy.copy(self.get_next_node(curr,last_action))\n        return last_action\n    def _run(self,shared): p=self.prep(shared); o=self._orch(shared); return self.post(shared,p,o)\n    def post(self,shared,prep_res,exec_res): return exec_res\n\nclass BatchFlow(Flow):\n    def _run(self,shared):\n        pr=self.prep(shared) or []\n        for bp in pr: self._orch(shared,{**self.params,**bp})\n        return self.post(shared,pr,None)\n\nclass AsyncNode(Node):\n    async def prep_async(self,shared): pass\n    async def exec_async(self,prep_res): pass\n    async def exec_fallback_async(self,prep_res,exc): raise exc\n    async def post_async(self,shared,prep_res,exec_res): pass\n    async def _exec(self,prep_res): \n        for i in range(self.max_retries):\n            try: return await self.exec_async(prep_res)\n            except Exception as e:\n                if i==self.max_retries-1: return await self.exec_fallback_async(prep_res,e)\n                if self.wait>0: await asyncio.sleep(self.wait)\n    async def run_async(self,shared): \n        if self.successors: warnings.warn(\"Node won't run successors. Use AsyncFlow.\")  \n        return await self._run_async(shared)\n    async def _run_async(self,shared): p=await self.prep_async(shared); e=await self._exec(p); return await self.post_async(shared,p,e)\n    def _run(self,shared): raise RuntimeError(\"Use run_async.\")\n\nclass AsyncBatchNode(AsyncNode,BatchNode):\n    async def _exec(self,items): return [await super(AsyncBatchNode,self)._exec(i) for i in items]\n\nclass AsyncParallelBatchNode(AsyncNode,BatchNode):\n    async def _exec(self,items): return await asyncio.gather(*(super(AsyncParallelBatchNode,self)._exec(i) for i in items))\n\nclass AsyncFlow(Flow,AsyncNode):\n    async def _orch_async(self,shared,params=None):\n        curr,p,last_action =copy.copy(self.start_node),(params or {**self.params}),None\n        while curr: curr.set_params(p); last_action=await curr._run_async(shared) if isinstance(curr,AsyncNode) else curr._run(shared); curr=copy.copy(self.get_next_node(curr,last_action))\n        return last_action\n    async def _run_async(self,shared): p=await self.prep_async(shared); o=await self._orch_async(shared); return await self.post_async(shared,p,o)\n    async def post_async(self,shared,prep_res,exec_res): return exec_res\n\nclass AsyncBatchFlow(AsyncFlow,BatchFlow):\n    async def _run_async(self,shared):\n        pr=await self.prep_async(shared) or []\n        for bp in pr: await self._orch_async(shared,{**self.params,**bp})\n        return await self.post_async(shared,pr,None)\n\nclass AsyncParallelBatchFlow(AsyncFlow,BatchFlow):\n    async def _run_async(self,shared): \n        pr=await self.prep_async(shared) or []\n        await asyncio.gather(*(self._orch_async(shared,{**self.params,**bp}) for bp in pr))\n        return await self.post_async(shared,pr,None)\n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `/tmp/PocketFlow/pocketflow/__init__.py`**\n\n---\n\n### 1. Primary Purpose\n\nThis code unit provides a flexible and extensible framework for defining, running, and composing computational nodes and flows (pipelines) both synchronously and asynchronously, with support for error-handling, conditional transitions, parameter injection, and batch processing. It defines a set of base classes and utilities for constructing data processing graphs where nodes perform computations and transitions can be conditioned on outcomes.\n\n---\n\n### 2. Parameters\n\n- **Node/Basenode/Flow/BatchNode/AsyncNode/AsyncFlow etc.:**\n  - Nodes generally accept parameters for controlling repeats (`max_retries`), waiting times (`wait`), and node parameters (`params`).\n  - `Flow`/`BatchFlow`/`AsyncFlow`/`AsyncBatchFlow`: Optionally take a `start` node to initialize the flow.\n\n- **Per-method parameters:**\n  - Most `run`, `run_async`, `_run`, `_run_async` methods take a `shared` object (arbitrary shared data for the flow).\n  - Many methods support passing custom per-node parameters (`params`), batch items, actions, and control over transitions.\n\n---\n\n### 3. Return Values\n\n- Nodes (`run`, `_run`) typically return the result from the node's computation via `post`.\n- `Flow` instances return the result of the last node's execution in their run (or the aggregate, in batch variants—often `None` for aggregate).\n- Asynchronous variants (`run_async`, `_run_async`) return results via `await`.\n- Return type is arbitrary—it depends on the node's `exec`/`post` implementation (defaults are `None` unless overridden).\n\n---\n\n### 4. Internal Functions/Methods Called\n\n- **Standard Library:**  \n  - `asyncio.sleep`, `asyncio.gather`, `warnings.warn`, `copy.copy`, `time.sleep`\n- **Internally within code:**\n  - Node methods: `prep`, `exec`, `exec_fallback`, `post`, `_run`, `_exec`\n  - Asynchronous counterparts: `prep_async`, `exec_async`, `exec_fallback_async`, `post_async`, `_run_async`, `_exec`\n  - Transition and composition: `.next`, `.set_params`, `.get_next_node`, `.start`, `.start_node`\n  - Flow orchestration: `_orch` (synchronous), `_orch_async` (async)\n  - Operator overloading for nodes/flows: `__rshift__`, `__sub__`\n  - Batch variants iterate and call node/flow methods per item.\n\n---\n\n**In short:**  \nThis file implements a composable pipeline (\"flow\") pattern for data processing and workflow orchestration, supporting both sync and async use cases with extensible hooks for preparation, execution, failure handling, conditional routing, and postprocessing, along with facilities for handling batches and retries.",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-map-reduce/nodes.py'.\nUnit Name: nodes.py\n\nCode:\nfrom pocketflow import Node, BatchNode\nfrom utils import call_llm\nimport yaml\nimport os\n\nclass ReadResumesNode(Node):\n    \"\"\"Map phase: Read all resumes from the data directory into shared storage.\"\"\"\n    \n    def exec(self, _):\n        resume_files = {}\n        data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"data\")\n        \n        for filename in os.listdir(data_dir):\n            if filename.endswith(\".txt\"):\n                file_path = os.path.join(data_dir, filename)\n                with open(file_path, 'r', encoding='utf-8') as file:\n                    resume_files[filename] = file.read()\n        \n        return resume_files\n    \n    def post(self, shared, prep_res, exec_res):\n        shared[\"resumes\"] = exec_res\n        return \"default\"\n\n\nclass EvaluateResumesNode(BatchNode):\n    \"\"\"Batch processing: Evaluate each resume to determine if the candidate qualifies.\"\"\"\n    \n    def prep(self, shared):\n        return list(shared[\"resumes\"].items())\n    \n    def exec(self, resume_item):\n        \"\"\"Evaluate a single resume.\"\"\"\n        filename, content = resume_item\n        \n        prompt = f\"\"\"\nEvaluate the following resume and determine if the candidate qualifies for an advanced technical role.\nCriteria for qualification:\n- At least a bachelor's degree in a relevant field\n- At least 3 years of relevant work experience\n- Strong technical skills relevant to the position\n\nResume:\n{content}\n\nReturn your evaluation in YAML format:\n```yaml\ncandidate_name: [Name of the candidate]\nqualifies: [true/false]\nreasons:\n  - [First reason for qualification/disqualification]\n  - [Second reason, if applicable]\n```\n\"\"\"\n        response = call_llm(prompt)\n        \n        # Extract YAML content\n        yaml_content = response.split(\"```yaml\")[1].split(\"```\")[0].strip() if \"```yaml\" in response else response\n        result = yaml.safe_load(yaml_content)\n        \n        return (filename, result)\n\n    def post(self, shared, prep_res, exec_res_list):\n        shared[\"evaluations\"] = {filename: result for filename, result in exec_res_list}\n        return \"default\"\n\n\nclass ReduceResultsNode(Node):\n    \"\"\"Reduce node: Count and print out how many candidates qualify.\"\"\"\n    \n    def prep(self, shared):\n        return shared[\"evaluations\"]\n    \n    def exec(self, evaluations):\n        qualified_count = 0\n        total_count = len(evaluations)\n        qualified_candidates = []\n        \n        for filename, evaluation in evaluations.items():\n            if evaluation.get(\"qualifies\", False):\n                qualified_count += 1\n                qualified_candidates.append(evaluation.get(\"candidate_name\", \"Unknown\"))\n        \n        summary = {\n            \"total_candidates\": total_count,\n            \"qualified_count\": qualified_count,\n            \"qualified_percentage\": round(qualified_count / total_count * 100, 1) if total_count > 0 else 0,\n            \"qualified_names\": qualified_candidates\n        }\n        \n        return summary\n    \n    def post(self, shared, prep_res, exec_res):\n        shared[\"summary\"] = exec_res\n        \n        print(\"\\n===== Resume Qualification Summary =====\")\n        print(f\"Total candidates evaluated: {exec_res['total_candidates']}\")\n        print(f\"Qualified candidates: {exec_res['qualified_count']} ({exec_res['qualified_percentage']}%)\")\n        \n        if exec_res['qualified_names']:\n            print(\"\\nQualified candidates:\")\n            for name in exec_res['qualified_names']:\n                print(f\"- {name}\")\n        \n        return \"default\" \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of /tmp/PocketFlow/cookbook/pocketflow-map-reduce/nodes.py:**\n\n1. **Primary Purpose:**\n   - This code unit defines a Map-Reduce workflow for evaluating a set of resume text files to determine which candidates qualify for an advanced technical role. The workflow is split into three processing nodes: reading resumes, evaluating them using an LLM, and aggregating the results.\n\n2. **Parameters:**\n   - The core classes (`ReadResumesNode`, `EvaluateResumesNode`, and `ReduceResultsNode`) are derived from `Node` or `BatchNode` and are designed to be used within a dataflow system, where their methods (`exec`, `prep`, and `post`) interact with a shared state dictionary (`shared`) or receive input data relevant to each phase.  \n   - Method signatures:\n     - `exec(self, _)` in `ReadResumesNode`: Takes an unused parameter (denoted `_`).\n     - `prep(self, shared)`, `exec(self, resume_item)`, `post(self, shared, prep_res, exec_res)` in `EvaluateResumesNode`: Parameters relate to workflow state and items being processed.\n     - `prep(self, shared)`, `exec(self, evaluations)`, `post(self, shared, prep_res, exec_res)` in `ReduceResultsNode`: Parameters manage inputs and results at each compute step.\n\n3. **Return Values:**\n   - `ReadResumesNode.exec`: Returns a dictionary mapping resume filenames to their text content.\n   - `EvaluateResumesNode.prep`: Returns a list of `(filename, content)` tuples for each resume.\n   - `EvaluateResumesNode.exec`: Returns a tuple of filename and the parsed evaluation result from the LLM (as a dict).\n   - `EvaluateResumesNode.post`: Stores a dictionary of evaluations in shared state; returns string `\"default\"`.\n   - `ReduceResultsNode.exec`: Returns a summary dictionary containing total, qualified count, percentage, and names of qualified candidates.\n   - `post` methods generally update shared state and/or print results, returning `\"default\"` as a status.\n\n4. **Internal Functions/Methods Called:**\n   - `os.path.join`, `os.path.dirname`, `os.path.abspath`, `os.listdir`: For file and directory operations.\n   - `open`: For reading resume files.\n   - `call_llm`: Custom utility to send prompts to a language model.\n   - `yaml.safe_load`: For parsing YAML output returned from the LLM.\n   - Standard Python dictionary and list methods.\n   - Printing to console (`print`).\n\n**In summary:**  \nThe code provides a map-reduce pipeline for automated resume evaluation, reading raw text files, batch-evaluating them using an LLM (via prompts and YAML parsing), and then counting and displaying which candidates qualify according to preset criteria. The code heavily relies on file I/O, a custom LLM interface, and YAML parsing.",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-a2a/common/client/card_resolver.py'.\nUnit Name: card_resolver.py\n\nCode:\nimport httpx\nfrom common.types import (\n    AgentCard,\n    A2AClientJSONError,\n)\nimport json\n\n\nclass A2ACardResolver:\n    def __init__(self, base_url, agent_card_path=\"/.well-known/agent.json\"):\n        self.base_url = base_url.rstrip(\"/\")\n        self.agent_card_path = agent_card_path.lstrip(\"/\")\n\n    def get_agent_card(self) -> AgentCard:\n        with httpx.Client() as client:\n            response = client.get(self.base_url + \"/\" + self.agent_card_path)\n            response.raise_for_status()\n            try:\n                return AgentCard(**response.json())\n            except json.JSONDecodeError as e:\n                raise A2AClientJSONError(str(e)) from e\n\n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `/tmp/PocketFlow/cookbook/pocketflow-a2a/common/client/card_resolver.py`:**\n\n1. **Primary Purpose:**  \n   The code defines a class (`A2ACardResolver`) that retrieves and parses an agent configuration (\"agent card\") in JSON format from a remote URL, using HTTP GET requests.\n\n2. **Parameters:**  \n   - `base_url` (constructor): The base URL of the remote server from which to fetch the agent card.\n   - `agent_card_path` (constructor, optional): The path (default `/.well-known/agent.json`) appended to `base_url` to construct the full URL to fetch the agent card.\n\n3. **Return Value:**  \n   - The `get_agent_card` method returns an instance of `AgentCard` initialized with the JSON data retrieved from the remote server.\n   - If JSON decoding fails, it raises an `A2AClientJSONError`.\n\n4. **Internally Called Functions/Methods:**\n   - `httpx.Client()`\n   - `client.get(...)`\n   - `response.raise_for_status()`\n   - `response.json()`\n   - `AgentCard(**...)` (constructor)\n   - `json.JSONDecodeError`\n   - `A2AClientJSONError(...)`",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-tao/main.py'.\nUnit Name: main.py\n\nCode:\n# main.py\n\nfrom flow import create_tao_flow\n\ndef main():\n    \n    query = \"\"\"I need to understand the latest developments in artificial intelligence\"\"\"\n    \n    # Create shared data\n    shared = {\n        \"query\": query,\n        \"thoughts\": [],\n        \"observations\": [],\n        \"current_thought_number\": 0\n    }\n    \n    # Create and run flow\n    tao_flow = create_tao_flow()\n    tao_flow.run(shared)\n    \n    # Print final result\n    if \"final_answer\" in shared:\n        print(\"\\nFinal Answer:\")\n        print(shared[\"final_answer\"])\n    else:\n        print(\"\\nFlow did not produce a final answer\")\n\nif __name__ == \"__main__\":\n    main()\n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of main.py**\n\n1. **Primary Purpose:**  \n   The code serves as the entry point for running a TAO (Think, Act, Observe) flow on a user-defined query about the latest developments in artificial intelligence. It sets up shared state, executes the flow, and displays the final answer if available.\n\n2. **Parameters:**  \n   This script does not define any parameters for its main function or as command-line arguments. The query is hardcoded within the script.\n\n3. **Return Value:**  \n   The `main` function (and the script overall) does not return any value. It performs its work via side effects, specifically printing to standard output.\n\n4. **Internal Calls:**  \n   - `create_tao_flow()` (imported from the `flow` module): Used to create the TAO flow object.\n   - `tao_flow.run(shared)`: Runs the TAO flow using the shared data.\n   - `print()`: Standard output to display the final answer or a message if no answer is produced.",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-cli-hitl/flow.py'.\nUnit Name: flow.py\n\nCode:\nfrom pocketflow import Flow\nfrom nodes import GetTopicNode, GenerateJokeNode, GetFeedbackNode\n\ndef create_joke_flow() -> Flow:\n    \"\"\"Creates and returns the joke generation flow.\"\"\"\n    get_topic_node = GetTopicNode()\n    generate_joke_node = GenerateJokeNode()\n    get_feedback_node = GetFeedbackNode()\n\n    get_topic_node >> generate_joke_node\n    generate_joke_node >> get_feedback_node\n    get_feedback_node - \"Disapprove\" >> generate_joke_node\n\n    joke_flow = Flow(start=get_topic_node)\n    return joke_flow \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `flow.py` code unit:**\n\n1. **Primary Purpose:**  \n   The code defines a function to construct a conversational flow for generating jokes, collecting user feedback, and iterating based on feedback using PocketFlow's structures.\n\n2. **Parameters:**  \n   The `create_joke_flow` function does not accept any parameters.\n\n3. **Return Value:**  \n   The function returns a `Flow` object representing the joke generation and feedback process, with nodes connected to define the flow's steps, including a cycle for disapproved jokes.\n\n4. **Internally Called Functions/Methods:**  \n   - `GetTopicNode()` (constructor)\n   - `GenerateJokeNode()` (constructor)\n   - `GetFeedbackNode()` (constructor)\n   - `Flow()` (constructor, from `pocketflow`)\n   - Operator overloading for chaining nodes:\n     - `>>` for connecting nodes sequentially\n     - `- \"Disapprove\" >>` for conditional branching based on feedback\n\n**Overall, it sets up a simple interactive process: get topic → generate joke → get feedback → repeat joke generation if feedback is 'Disapprove'.**",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-multi-agent/utils.py'.\nUnit Name: utils.py\n\nCode:\nimport os\nfrom openai import OpenAI\n\ndef call_llm(prompt):    \n    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"your-api-key\"))\n    r = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return r.choices[0].message.content\n\n# Example usage\nif __name__ == \"__main__\":\n    print(call_llm(\"Tell me a short joke\")) \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `/tmp/PocketFlow/cookbook/pocketflow-multi-agent/utils.py`:**\n\n1. **Primary purpose:**  \n   This code unit provides a utility function to send a prompt to the OpenAI GPT-4o-mini language model via the OpenAI API and return its generated response. It is designed to facilitate easy interaction with an LLM (large language model) in Python scripts.\n\n2. **Parameters:**  \n   - The main function, `call_llm`, takes a single parameter:  \n     - `prompt` (string): The textual input that will be sent as a message to the language model.\n\n3. **Return value:**  \n   - The function returns the language model's response (string) corresponding to the prompt, extracted from the API's completion result.\n\n4. **Functions/methods called internally:**  \n   - `os.environ.get()`: Retrieves the OpenAI API key from environment variables.\n   - `OpenAI(api_key=...)`: Instantiates an OpenAI API client with the specified API key.\n   - `client.chat.completions.create(...)`: Sends the prompt to the specified GPT model and gets a completion.\n   - Accesses `r.choices[0].message.content` to extract the response content.  \n   \nThe script also includes an example usage block that runs `call_llm(\"Tell me a short joke\")` when executed directly.",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-chat-memory/utils/vector_index.py'.\nUnit Name: vector_index.py\n\nCode:\nimport numpy as np\nimport faiss\n\ndef create_index(dimension=1536):\n    return faiss.IndexFlatL2(dimension)\n\ndef add_vector(index, vector):\n    # Make sure the vector is a numpy array with the right shape for FAISS\n    vector = np.array(vector).reshape(1, -1).astype(np.float32)\n    \n    # Add the vector to the index\n    index.add(vector)\n    \n    # Return the position (index.ntotal is the total number of vectors in the index)\n    return index.ntotal - 1\n\ndef search_vectors(index, query_vector, k=1):\n    \"\"\"Search for the k most similar vectors to the query vector\n    \n    Args:\n        index: The FAISS index\n        query_vector: The query vector (numpy array or list)\n        k: Number of results to return (default: 1)\n        \n    Returns:\n        tuple: (indices, distances) where:\n            - indices is a list of positions in the index\n            - distances is a list of the corresponding distances\n    \"\"\"\n    # Make sure we don't try to retrieve more vectors than exist in the index\n    k = min(k, index.ntotal)\n    if k == 0:\n        return [], []\n        \n    # Make sure the query is a numpy array with the right shape for FAISS\n    query_vector = np.array(query_vector).reshape(1, -1).astype(np.float32)\n    \n    # Search the index\n    distances, indices = index.search(query_vector, k)\n    \n    return indices[0].tolist(), distances[0].tolist()\n\n# Example usage\nif __name__ == \"__main__\":\n    # Create a new index\n    index = create_index(dimension=3)\n    \n    # Add some random vectors and track them separately\n    items = []\n    for i in range(5):\n        vector = np.random.random(3)\n        position = add_vector(index, vector)\n        items.append(f\"Item {i}\")\n        print(f\"Added vector at position {position}\")\n        \n    print(f\"Index contains {index.ntotal} vectors\")\n    \n    # Search for a similar vector\n    query = np.random.random(3)\n    indices, distances = search_vectors(index, query, k=2)\n    \n    print(\"Query:\", query)\n    print(\"Found indices:\", indices)\n    print(\"Distances:\", distances)\n    print(\"Retrieved items:\", [items[idx] for idx in indices]) \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `vector_index.py`**\n\n1. **Primary purpose:**  \n   The code provides utility functions for creating and using a FAISS-based vector index. It enables storage, retrieval, and similarity search of high-dimensional vectors, suitable for applications like semantic search or embedding-based memory.\n\n2. **Brief parameter description:**  \n   - `create_index(dimension=1536)`:  \n     - `dimension` (int): The dimensionality of vectors the index will store (defaults to 1536).\n   - `add_vector(index, vector)`:  \n     - `index`: The FAISS index object.\n     - `vector`: The vector to add (list or numpy array).\n   - `search_vectors(index, query_vector, k=1)`:  \n     - `index`: The FAISS index object.\n     - `query_vector`: The vector to query (list or numpy array).\n     - `k` (int): Number of nearest vectors to retrieve (defaults to 1).\n\n3. **Brief description of return values:**  \n   - `create_index`: Returns a new FAISS L2 index.\n   - `add_vector`: Returns the position (int) at which the vector was added to the index.\n   - `search_vectors`: Returns a tuple `(indices, distances)` where:\n     - `indices`: List of index positions for the most similar vectors.\n     - `distances`: List of L2 distances for the corresponding vectors.\n\n4. **Other functions or methods called internally:**\n   - `np.array`, `np.float32`, `np.random.random`, `np.reshape` (from `numpy`)\n   - `faiss.IndexFlatL2`, `index.add()`, `index.search()`, `index.ntotal` (from `faiss`)\n   - Standard Python list operations and print functions (in the example usage block)",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-hello-world/utils/__init__.py'.\nUnit Name: __init__.py\n\nCode:\n\n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "It appears the code unit you referenced—/tmp/PocketFlow/cookbook/pocketflow-hello-world/utils/__init__.py—does not contain any code; you have presented an empty code block.\n\n**Summary:**\n1. **Primary purpose:**  \n   This file, in its current empty state, serves as an implicit initializer for the utils Python package, making the package importable. It does not add any logic or functionality by itself.\n\n2. **Parameters:**  \n   There are no parameters, as there are no functions, classes, or code in the file.\n\n3. **Return value:**  \n   There are no return values, as the file contains no executable code.\n\n4. **Other functions/methods called internally:**  \n   None, since there is no code present.\n\nIf you intended to analyze specific code, please provide it in the code block.",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-text2sql/utils/call_llm.py'.\nUnit Name: call_llm.py\n\nCode:\nimport os\nfrom openai import OpenAI\n\ndef call_llm(prompt):    \n    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"your-api-key\"))\n    r = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return r.choices[0].message.content\n\n# Example usage\nif __name__ == \"__main__\":\n    print(call_llm(\"Tell me a short joke\")) \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `/tmp/PocketFlow/cookbook/pocketflow-text2sql/utils/call_llm.py`:**\n\n1. **Primary purpose:**  \n   The code defines a utility function to interact with the OpenAI API, sending a text prompt to the GPT-4o language model and retrieving its response.\n\n2. **Parameters:**  \n   - The function `call_llm` takes a single parameter:  \n     - `prompt` (str): The text input or question to send to the language model.\n\n3. **Return value:**  \n   - The function returns the content of the model's response (str): the generated reply to the input prompt.\n\n4. **Functions/methods called internally:**  \n   - `os.environ.get()` (from the `os` module)\n   - `OpenAI()` constructor (from the `openai` package)  \n   - `client.chat.completions.create()` (method for generating a completion using the model)\n\n**Note:**  \nThere is also a main block that demonstrates usage by printing the model's response to the prompt \"Tell me a short joke\".",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-async-basic/flow.py'.\nUnit Name: flow.py\n\nCode:\n\"\"\"AsyncFlow implementation for recipe finder.\"\"\"\n\nfrom pocketflow import AsyncFlow, Node\nfrom nodes import FetchRecipes, SuggestRecipe, GetApproval\n\nclass NoOp(Node):\n    \"\"\"Node that does nothing, used to properly end the flow.\"\"\"\n    pass\n\ndef create_flow():\n    \"\"\"Create and connect nodes into a flow.\"\"\"\n    \n    # Create nodes\n    fetch = FetchRecipes()\n    suggest = SuggestRecipe()\n    approve = GetApproval()\n    end = NoOp()\n    \n    # Connect nodes\n    fetch - \"suggest\" >> suggest\n    suggest - \"approve\" >> approve\n    approve - \"retry\" >> suggest  # Loop back for another suggestion\n    approve - \"accept\" >> end     # Properly end the flow\n    \n    # Create flow starting with fetch\n    flow = AsyncFlow(start=fetch)\n    return flow \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of code unit `flow.py`:**\n\n1. **Primary purpose:**  \n   This code defines the asynchronous control flow for a recipe finder application using the `AsyncFlow` framework. It organizes how various tasks and user interactions (fetching, suggesting, and approving recipes) are sequenced and interconnected.\n\n2. **Parameters:**  \n   - The `create_flow()` function does **not** take any parameters.\n\n3. **Return value:**  \n   - The `create_flow()` function returns an `AsyncFlow` object representing the constructed flow, starting with the `FetchRecipes` node and moving through suggestion, approval, and completion steps.\n\n4. **Internally called functions/methods:**  \n   - `FetchRecipes()` (class constructor from `nodes`)\n   - `SuggestRecipe()` (class constructor from `nodes`)\n   - `GetApproval()` (class constructor from `nodes`)\n   - `NoOp()` (local class constructor)\n   - `AsyncFlow(start=...)` (from `pocketflow`)  \n   - Overloaded operators on node objects for connecting flow:  \n     - `- \"suggest\" >> suggest`\n     - `- \"approve\" >> approve`\n     - `- \"retry\" >> suggest`\n     - `- \"accept\" >> end`",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/cookbook/pocketflow-google-calendar/nodes.py'.\nUnit Name: nodes.py\n\nCode:\nfrom pocketflow import Node\nfrom utils.google_calendar import create_event, list_events, list_calendar_lists\nfrom datetime import datetime, timedelta\n\nclass CreateCalendarEventNode(Node):\n    def prep(self, shared):\n        \"\"\"Prepares the necessary data to create an event.\"\"\"\n        return {\n            'summary': shared.get('event_summary'),\n            'description': shared.get('event_description'),\n            'start_time': shared.get('event_start_time'),\n            'end_time': shared.get('event_end_time')\n        }\n    \n    def exec(self, event_data):\n        \"\"\"Creates a new calendar event.\"\"\"\n        try:\n            event = create_event(\n                summary=event_data['summary'],\n                description=event_data['description'],\n                start_time=event_data['start_time'],\n                end_time=event_data['end_time']\n            )\n            return {'success': True, 'event': event}\n        except Exception as e:\n            return {'success': False, 'error': str(e)}\n    \n    def post(self, shared, prep_res, exec_res):\n        \"\"\"Stores the event creation result.\"\"\"\n        if exec_res['success']:\n            shared['last_created_event'] = exec_res['event']\n            return 'success'\n        else:\n            shared['error'] = exec_res['error']\n            return 'error'\n\nclass ListCalendarEventsNode(Node):\n    def prep(self, shared):\n        \"\"\"Prepares parameters to list events.\"\"\"\n        return {\n            'days': shared.get('days_to_list', 7)\n        }\n    \n    def exec(self, params):\n        \"\"\"Lists calendar events.\"\"\"\n        try:\n            events = list_events(days=params['days'])\n            return {'success': True, 'events': events}\n        except Exception as e:\n            return {'success': False, 'error': str(e)}\n    \n    def post(self, shared, prep_res, exec_res):\n        \"\"\"Stores the list of events.\"\"\"\n        if exec_res['success']:\n            shared['calendar_events'] = exec_res['events']\n            return 'success'\n        else:\n            shared['error'] = exec_res['error']\n            return 'error'\n\nclass ListCalendarsNode(Node):\n    def prep(self, shared):\n        \"\"\"No special preparation needed to list calendars.\"\"\"\n        return {}\n\n    def exec(self, params):\n        \"\"\"Lists all available calendars for the user.\"\"\"\n        try:\n            calendars = list_calendar_lists()\n            return {'success': True, 'calendars': calendars}\n        except Exception as e:\n            return {'success': False, 'error': str(e)}\n\n    def post(self, shared, prep_res, exec_res):\n        \"\"\"Stores the list of calendars in the shared store.\"\"\"\n        if exec_res['success']:\n            shared['available_calendars'] = exec_res['calendars']\n            return 'success'\n        else:\n            shared['error'] = exec_res['error']\n            return 'error' \n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `nodes.py`**\n\n1. **Primary Purpose:**  \n   This code defines a set of Node classes for integrating Google Calendar operations into a PocketFlow workflow. These Node classes encapsulate the logic for creating a calendar event, listing calendar events, and listing available calendars for a user, to be used as modular workflow steps.\n\n2. **Parameters:**  \n   - Each Node class has methods (`prep`, `exec`, and `post`) that work with dictionaries:\n     - The `prep` method receives a `shared` dictionary containing workflow state or inputs, and prepares the necessary parameters for the operation.\n     - The `exec` method receives parameters prepared by `prep` (such as event details or listing parameters).\n     - The `post` method receives `shared`, the preparation result, and the execution result to update the workflow state or capture errors.\n   - Specific expected keys in `shared` include:  \n     - `'event_summary'`, `'event_description'`, `'event_start_time'`, `'event_end_time'` for event creation.  \n     - `'days_to_list'` for listing events.\n\n3. **Return Values:**  \n   - The `prep` and `exec` methods return dictionaries with relevant data for the step (such as event parameters, a list of events/calendars, or error info).\n   - The `post` methods update the `shared` state in place and return a status string: either `'success'` or `'error'`.\n\n4. **Other Functions/Methods Called Internally:**  \n   - `create_event` from `utils.google_calendar`\n   - `list_events` from `utils.google_calendar`\n   - `list_calendar_lists` from `utils.google_calendar`\n\nThese classes enable adding Google Calendar operations to workflows in a structured, error-tolerant way, relying on helper functions for the actual Google API interactions.",
  "\nAnalyze the following code unit from the file '/tmp/PocketFlow/tests/test_flow_basic.py'.\nUnit Name: test_flow_basic.py\n\nCode:\n# tests/test_flow_basic.py\nimport unittest\nimport sys\nfrom pathlib import Path\nimport warnings\n\nsys.path.insert(0, str(Path(__file__).parent.parent))\nfrom pocketflow import Node, Flow\n\n# --- Node Definitions ---\n# Nodes intended for default transitions (>>) should NOT return a specific\n# action string from post. Let it return None by default.\n# Nodes intended for conditional transitions (-) MUST return the action string.\n\nclass NumberNode(Node):\n    def __init__(self, number):\n        super().__init__()\n        self.number = number\n    def prep(self, shared_storage):\n        shared_storage['current'] = self.number\n    # post implicitly returns None - used for default transition\n\nclass AddNode(Node):\n    def __init__(self, number):\n        super().__init__()\n        self.number = number\n    def prep(self, shared_storage):\n        shared_storage['current'] += self.number\n    # post implicitly returns None - used for default transition\n\nclass MultiplyNode(Node):\n    def __init__(self, number):\n        super().__init__()\n        self.number = number\n    def prep(self, shared_storage):\n        shared_storage['current'] *= self.number\n    # post implicitly returns None - used for default transition\n\nclass CheckPositiveNode(Node):\n   # This node IS designed for conditional branching\n   def prep(self, shared_storage):\n       pass\n   def post(self, shared_storage, prep_result, proc_result):\n        # MUST return the specific action string for branching\n        if shared_storage['current'] >= 0:\n            return 'positive'\n        else:\n            return 'negative'\n\nclass NoOpNode(Node):\n    # Just a placeholder node\n    pass # post implicitly returns None\n\nclass EndSignalNode(Node):\n    # A node specifically to return a value when it's the end\n    def __init__(self, signal=\"finished\"):\n        super().__init__()\n        self.signal = signal\n    def post(self, shared_storage, prep_result, exec_result):\n        return self.signal # Return a specific signal\n\n# --- Test Class ---\nclass TestFlowBasic(unittest.TestCase):\n\n    def test_start_method_initialization(self):\n        \"\"\"Test initializing flow with start() after creation.\"\"\"\n        shared_storage = {}\n        n1 = NumberNode(5)\n        pipeline = Flow()\n        pipeline.start(n1)\n        last_action = pipeline.run(shared_storage)\n        self.assertEqual(shared_storage['current'], 5)\n        # NumberNode.post returns None (default)\n        self.assertIsNone(last_action)\n\n    def test_start_method_chaining(self):\n        \"\"\"Test fluent chaining using start().next()...\"\"\"\n        shared_storage = {}\n        pipeline = Flow()\n        # Chain: NumberNode -> AddNode -> MultiplyNode\n        # All use default transitions (post returns None)\n        pipeline.start(NumberNode(5)).next(AddNode(3)).next(MultiplyNode(2))\n        last_action = pipeline.run(shared_storage)\n        self.assertEqual(shared_storage['current'], 16)\n        # Last node (MultiplyNode) post returns None\n        self.assertIsNone(last_action)\n\n    def test_sequence_with_rshift(self):\n        \"\"\"Test a simple linear pipeline using >>\"\"\"\n        shared_storage = {}\n        n1 = NumberNode(5)\n        n2 = AddNode(3)\n        n3 = MultiplyNode(2)\n\n        pipeline = Flow()\n        # All default transitions (post returns None)\n        pipeline.start(n1) >> n2 >> n3\n\n        last_action = pipeline.run(shared_storage)\n        self.assertEqual(shared_storage['current'], 16)\n        # Last node (n3: MultiplyNode) post returns None\n        self.assertIsNone(last_action)\n\n    def test_branching_positive(self):\n        \"\"\"Test positive branch: CheckPositiveNode returns 'positive'\"\"\"\n        shared_storage = {}\n        start_node = NumberNode(5)    # post -> None\n        check_node = CheckPositiveNode() # post -> 'positive' or 'negative'\n        add_if_positive = AddNode(10) # post -> None\n        add_if_negative = AddNode(-20) # post -> None (won't run)\n\n        pipeline = Flow()\n        # start -> check (default); check branches on 'positive'/'negative'\n        pipeline.start(start_node) >> check_node\n        check_node - \"positive\" >> add_if_positive\n        check_node - \"negative\" >> add_if_negative\n\n        # Execution: start_node -> check_node -> add_if_positive\n        last_action = pipeline.run(shared_storage)\n        self.assertEqual(shared_storage['current'], 15) # 5 + 10\n        # Last node executed was add_if_positive, its post returns None\n        self.assertIsNone(last_action)\n\n    def test_branching_negative(self):\n        \"\"\"Test negative branch: CheckPositiveNode returns 'negative'\"\"\"\n        shared_storage = {}\n        start_node = NumberNode(-5)   # post -> None\n        check_node = CheckPositiveNode() # post -> 'positive' or 'negative'\n        add_if_positive = AddNode(10) # post -> None (won't run)\n        add_if_negative = AddNode(-20) # post -> None\n\n        pipeline = Flow()\n        pipeline.start(start_node) >> check_node\n        check_node - \"positive\" >> add_if_positive\n        check_node - \"negative\" >> add_if_negative\n\n        # Execution: start_node -> check_node -> add_if_negative\n        last_action = pipeline.run(shared_storage)\n        self.assertEqual(shared_storage['current'], -25) # -5 + -20\n        # Last node executed was add_if_negative, its post returns None\n        self.assertIsNone(last_action)\n\n    def test_cycle_until_negative_ends_with_signal(self):\n        \"\"\"Test cycle, ending on a node that returns a signal\"\"\"\n        shared_storage = {}\n        n1 = NumberNode(10)           # post -> None\n        check = CheckPositiveNode()   # post -> 'positive' or 'negative'\n        subtract3 = AddNode(-3)       # post -> None\n        end_node = EndSignalNode(\"cycle_done\") # post -> \"cycle_done\"\n\n        pipeline = Flow()\n        pipeline.start(n1) >> check\n        # Branching from CheckPositiveNode\n        check - 'positive' >> subtract3\n        check - 'negative' >> end_node # End on negative branch\n        # After subtracting, go back to check (default transition)\n        subtract3 >> check\n\n        # Execution: n1->check->sub3->check->sub3->check->sub3->check->sub3->check->end_node\n        last_action = pipeline.run(shared_storage)\n        self.assertEqual(shared_storage['current'], -2) # 10 -> 7 -> 4 -> 1 -> -2\n        # Last node executed was end_node, its post returns \"cycle_done\"\n        self.assertEqual(last_action, \"cycle_done\")\n\n    def test_flow_ends_warning_default_missing(self):\n        \"\"\"Test warning when default transition is needed but not found\"\"\"\n        shared_storage = {}\n        # Node that returns a specific action from post\n        class ActionNode(Node):\n            def post(self, *args): return \"specific_action\"\n        start_node = ActionNode()\n        next_node = NoOpNode()\n\n        pipeline = Flow()\n        pipeline.start(start_node)\n        # Define successor only for the specific action\n        start_node - \"specific_action\" >> next_node\n\n        # Make start_node return None instead, triggering default search\n        start_node.post = lambda *args: None\n\n        with warnings.catch_warnings(record=True) as w:\n            warnings.simplefilter(\"always\")\n            # Run flow. start_node runs, post returns None.\n            # Flow looks for \"default\", but only \"specific_action\" exists.\n            last_action = pipeline.run(shared_storage)\n\n            self.assertEqual(len(w), 1)\n            self.assertTrue(issubclass(w[-1].category, UserWarning))\n            # Warning message should indicate \"default\" wasn't found\n            self.assertIn(\"Flow ends: 'None' not found in ['specific_action']\", str(w[-1].message))\n        # Last action is from start_node's post\n        self.assertIsNone(last_action)\n\n    def test_flow_ends_warning_specific_missing(self):\n        \"\"\"Test warning when specific action is returned but not found\"\"\"\n        shared_storage = {}\n        # Node that returns a specific action from post\n        class ActionNode(Node):\n            def post(self, *args): return \"specific_action\"\n        start_node = ActionNode()\n        next_node = NoOpNode()\n\n        pipeline = Flow()\n        pipeline.start(start_node)\n        # Define successor only for \"default\"\n        start_node >> next_node # same as start_node.next(next_node, \"default\")\n\n        with warnings.catch_warnings(record=True) as w:\n            warnings.simplefilter(\"always\")\n            # Run flow. start_node runs, post returns \"specific_action\".\n            # Flow looks for \"specific_action\", but only \"default\" exists.\n            last_action = pipeline.run(shared_storage)\n\n            self.assertEqual(len(w), 1)\n            self.assertTrue(issubclass(w[-1].category, UserWarning))\n            # Warning message should indicate \"specific_action\" wasn't found\n            self.assertIn(\"Flow ends: 'specific_action' not found in ['default']\", str(w[-1].message))\n        # Last action is from start_node's post\n        self.assertEqual(last_action, \"specific_action\")\n\n\nif __name__ == '__main__':\n    unittest.main()\n\nYour task is to provide a concise, natural language summary that includes:\n1. The primary purpose of the code unit.\n2. A brief description of its parameters (if any).\n3. A brief description of its return value (if any).\n4. A list of other functions or methods it calls internally.\n": "**Summary of `/tmp/PocketFlow/tests/test_flow_basic.py`:**\n\n---\n\n**1. Primary purpose:**  \nThis code unit implements a suite of unit tests for the PocketFlow library's `Flow` system, verifying the correct behavior of node sequencing, conditional (branched) transitions, and warning signals when transitions are missing or misconfigured. It tests the core mechanics of constructing and running directed flows of `Node` objects with both default and conditional transitions.\n\n**2. Parameters:**  \nThis is a test file using Python's `unittest` framework. The individual test methods generally take no parameters except for `self` (typical for `unittest.TestCase`). Some inner classes or methods (like custom Node subclasses) accept parameters such as `number` or `signal`, used to initialize node state. The main shared \"parameter\" within tests is the `shared_storage` dictionary, which is passed to the flow execution to store computation state.\n\n**3. Return value:**  \nThe test methods do not return any values (standard for `unittest`), but the various flow executions (`pipeline.run(shared_storage)`) return the last action string generated by the last node's `post` method in the flow. This is checked with assertions, but is not returned from the test methods.\n\n**4. Other functions or methods called internally:**  \nInternal calls within the test code and custom node classes include:\n- `Node.__init__`, `Node.prep`, `Node.post` (via custom subclasses and Flow execution)\n- `Flow()`, `Flow.start()`, `Flow.next()` (via `.next()` or `>>`)\n- Transition linkage operators: `>>` (for default transitions), `-`/`>>` (for conditional branching)\n- `Flow.run(shared_storage)` to execute the constructed flow\n- `unittest.TestCase` methods:\n  - `self.assertEqual`\n  - `self.assertIsNone`\n  - `self.assertTrue`\n  - `self.assertIn`\n- Warnings handling via the `warnings` module:\n  - `warnings.catch_warnings`\n  - `warnings.simplefilter`\n- File and path manipulation via `sys.path` and `pathlib.Path` (for import setup)\n- The test code also uses custom inner classes like `NumberNode`, `AddNode`, `MultiplyNode`, `CheckPositiveNode`, `NoOpNode`, and `EndSignalNode` as stubs/mocks for flow node behaviors.\n\n**In summary:**  \nThis unit is dedicated to testing the correct functioning of PocketFlow's flow composition and execution system. It verifies sequential and branching transitions between nodes, correct update of shared state, action return values, and appropriate warnings when transitions are missing. The test file wraps its checks in methods using the standard unittest framework, with no external parameters or return values beyond those used internally for assertions."
}